{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import h5py\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://stackoverflow.com/questions/41176258/h5py-access-data-in-datasets-in-svhn\n",
    "\n",
    "def get_box_data(index, hdf5_data):\n",
    "    \"\"\"\n",
    "    get `left, top, width, height` of each picture\n",
    "    :param index:\n",
    "    :param hdf5_data:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    meta_data = dict()\n",
    "    meta_data['height'] = []\n",
    "    meta_data['label'] = []\n",
    "    meta_data['left'] = []\n",
    "    meta_data['top'] = []\n",
    "    meta_data['width'] = []\n",
    "\n",
    "    def print_attrs(name, obj):\n",
    "        vals = []\n",
    "        if obj.shape[0] == 1:\n",
    "            vals.append(obj[0][0])\n",
    "        else:\n",
    "            for k in range(obj.shape[0]):\n",
    "                vals.append(int(hdf5_data[obj[k][0]][0][0]))\n",
    "        meta_data[name] = vals\n",
    "\n",
    "    box = hdf5_data['/digitStruct/bbox'][index]\n",
    "    hdf5_data[box[0]].visititems(print_attrs)\n",
    "    return meta_data\n",
    "\n",
    "def get_name(index, hdf5_data):\n",
    "    name = hdf5_data['/digitStruct/name']\n",
    "    return ''.join([chr(v[0]) for v in hdf5_data[name[index][0]].value])\n",
    "\n",
    "\n",
    "def aggregate_data(index, hdf5_data):\n",
    "    \n",
    "    image_id = get_name(index, mat_data)\n",
    "    labels = get_box_data(index, mat_data)\n",
    "    \n",
    "    # Convert label 10 to label 0 for digit 0\n",
    "    if 10 in labels['label']:\n",
    "        labels['label'] = [0 if x==10 else x for x in labels['label']]\n",
    "        \n",
    "    metadata = {}\n",
    "    \n",
    "    metadata['filename'] = image_id\n",
    "    metadata['metadata'] = labels\n",
    "\n",
    "    return metadata\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download SVHN data in to /data/SVHN/\n",
    "# Parse all metadata from digitStruct.mat into metadata dict (long!)\n",
    "\n",
    "file1 = 'data/SVHN/train/digitStruct.mat'\n",
    "mat_data = h5py.File(file1)\n",
    "size = mat_data['/digitStruct/name'].size\n",
    "\n",
    "\n",
    "metadata = {}\n",
    "for index in range(size):\n",
    "    \n",
    "    metadata[index] = aggregate_data(index, mat_data)\n",
    "\n",
    "    if index % 1000 == 0 and index != 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create custom dataloader.\n",
    "\n",
    "https://stanford.edu/~shervine/blog/pytorch-how-to-generate-data-parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "\n",
    "class SVHNDataset(data.Dataset):\n",
    "    \n",
    "    def __init__(self, metadata, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            labels (dict): Dictionary containing all labels and metadata\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.metadata = metadata\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        index : int\n",
    "            The index of the dataset\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        X : PIL objet\n",
    "        \n",
    "        y : dict\n",
    "            The metadata associated to the image in dict form.\n",
    "\n",
    "        '''\n",
    "        'Generates one sample of data'\n",
    "\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.metadata[index]['filename'])\n",
    "\n",
    "        # Load data and get label\n",
    "        X = Image.open(img_name)\n",
    "        y = self.metadata[index]['metadata']\n",
    "\n",
    "        return X, y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = 'data/SVHN/train/'\n",
    "traindata = SVHNDataset(metadata, root_dir)\n",
    "\n",
    "X, y = traindata[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Draft code to extract bboxes\n",
    "\n",
    "N = len(y['label'])\n",
    "labels = []\n",
    "boxes = []\n",
    "\n",
    "for jj in range(N):\n",
    "    labels.append(y['label'][jj])\n",
    "    y1 = y['top'][jj]\n",
    "    y2 = y['top'][jj]+y['height'][jj]\n",
    "    x1 = y['left'][jj]\n",
    "    x2 = x1 + y['width'][jj]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text-id",
   "language": "python",
   "name": "text-id"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
